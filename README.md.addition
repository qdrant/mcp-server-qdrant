## OpenAI Embedding Models

As of version 0.8.0, the server now supports OpenAI embedding models through the OpenAI API. You can use models such as `text-embedding-3-small`, `text-embedding-3-large`, and `text-embedding-ada-002`.

### Configuration

To use OpenAI embedding models, set the following environment variables:

| Name                 | Description                                         | Example Value                 |
|----------------------|-----------------------------------------------------|-------------------------------|
| `EMBEDDING_PROVIDER` | The embedding provider to use                       | `openai`                      |
| `EMBEDDING_MODEL`    | The OpenAI model to use for embeddings              | `text-embedding-3-small`      |
| `OPENAI_API_KEY`     | Your OpenAI API key                                 | `sk-...`                      |

### Example Usage

```bash
QDRANT_URL="http://localhost:6333" \
COLLECTION_NAME="my-collection" \
EMBEDDING_PROVIDER="openai" \
EMBEDDING_MODEL="text-embedding-3-small" \
OPENAI_API_KEY="your-openai-api-key" \
uvx mcp-server-qdrant
```

### Supported Models

| Model Name             | Dimensions | Best For                                      |
|------------------------|------------|-----------------------------------------------|
| text-embedding-3-small | 1536       | Most use cases                                |
| text-embedding-3-large | 3072       | Highest accuracy but more expensive           |
| text-embedding-ada-002 | 1536       | Legacy model (consider using newer ones)      |

### Cost Considerations

Unlike the built-in FastEmbed models, OpenAI models require API calls that have associated costs. Please refer to [OpenAI's pricing page](https://openai.com/pricing) for the current rates.